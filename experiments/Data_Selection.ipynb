{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading all datasets into memory\n",
    "items = pd.read_csv('../data/raw/olist_order_items_dataset.csv', encoding='utf-8')\n",
    "sellers = pd.read_csv('../data/raw/olist_sellers_dataset.csv', encoding='utf-8')\n",
    "leads = pd.read_csv('../data/raw/olist_marketing_qualified_leads_dataset.csv', encoding='utf-8')\n",
    "deals = pd.read_csv('../data/raw/olist_closed_deals_dataset.csv', encoding='utf-8')\n",
    "orders = pd.read_csv('../data/raw/olist_orders_dataset.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dropping unnecessary variables of dataframes\n",
    "items = items.drop(['shipping_limit_date'], axis=1)\n",
    "sellers = sellers.drop(['seller_city', 'seller_zip_code_prefix'], axis=1)\n",
    "deals = deals.drop(['sdr_id','sr_id'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merging deals and leads to marketing dataset\n",
    "marketing = leads.merge(deals, on='mql_id', how='left')\n",
    "marketing = marketing.dropna(subset=['seller_id']).set_index('mql_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transform \"declared\"-Variables into boolean variables\n",
    "marketing.declared_monthly_revenue = marketing.declared_monthly_revenue.replace(to_replace=0.0 ,value= np.nan)\n",
    "marketing['declare_revenue'] = ['False' if pd.isna(x) == True else 'True' for x in marketing.declared_monthly_revenue]\n",
    "marketing['declare_opc'] = ['False' if pd.isna(x) == True else 'True' for x in marketing.declared_product_catalog_size]\n",
    "marketing = marketing.drop(['declared_monthly_revenue','declared_product_catalog_size'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transform average_stock into boolean variable due to only 62 filled cases\n",
    "marketing.average_stock = marketing.average_stock.replace(to_replace= ['unknown'] ,value= np.nan)\n",
    "marketing['has_stock'] = ['False' if pd.isna(x) == True else 'True' for x in marketing.average_stock]\n",
    "marketing = marketing.drop('average_stock', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Complete 'has'-Variables with fill out NaNs into false statements\n",
    "marketing.has_company = marketing.has_company.replace(to_replace= [np.nan] ,value= 'false')\n",
    "marketing.has_gtin = marketing.has_gtin.replace(to_replace= [np.nan] ,value= 'false')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transform contact_date and won_date into calculated days2conversion\n",
    "marketing.first_contact_date = pd.to_datetime(marketing.first_contact_date).dt.date.astype('datetime64')\n",
    "marketing.won_date = pd.to_datetime(marketing.won_date).dt.date.astype('datetime64')\n",
    "marketing['days2conversion'] = (marketing.won_date - marketing.first_contact_date).dt.days\n",
    "marketing = marketing.drop(['won_date','first_contact_date'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert \"unknown\" category in origin to NANs\n",
    "marketing.origin = marketing.origin.replace(to_replace=['unknown'], value=np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merging orders with sellers and items dataset to commerce\n",
    "commerce = pd.merge(orders, items, on='order_id')\n",
    "commerce = commerce.merge(sellers, on='seller_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculation of sales volume per unique seller id\n",
    "orders_revenues = commerce[['order_id','price']].groupby(by=commerce.order_id).sum()\n",
    "commerce = commerce.merge(orders_revenues,on='order_id')\n",
    "seller_revenues = commerce[['seller_id', 'price_y']].groupby(commerce.seller_id).sum().round(2)\n",
    "seller_revenues =  dict(zip(seller_revenues.index,seller_revenues.price_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculation of customer orders per unique seller id\n",
    "unique_sellers = commerce.seller_id.unique()\n",
    "counts = []\n",
    "\n",
    "for seller in unique_sellers:\n",
    "    counter = 0\n",
    "\n",
    "    for row in commerce.seller_id:\n",
    "        if row == seller:\n",
    "            counter += 1\n",
    "        else:\n",
    "            counter = counter\n",
    "    \n",
    "    counts.append(counter)\n",
    "\n",
    "seller_orders = dict(zip(unique_sellers,counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculation of last order activity per unique seller id\n",
    "latest = max(pd.to_datetime(commerce.order_purchase_timestamp).dt.date)\n",
    "start = min(pd.to_datetime(commerce.order_purchase_timestamp).dt.date)\n",
    "timestamps = {}\n",
    "\n",
    "for seller, time in zip(commerce.seller_id, pd.to_datetime(commerce.order_purchase_timestamp).dt.date):\n",
    "    if seller in timestamps:\n",
    "        if time > timestamps[seller]:\n",
    "            timestamps[seller] = time\n",
    "        else:\n",
    "            timestamps[seller] = timestamps[seller]\n",
    "    else:\n",
    "        timestamps[seller] = start\n",
    "\n",
    "for key in timestamps:\n",
    "    timestamps[key] = (latest - timestamps[key]).days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = pd.DataFrame()\n",
    "scores['seller_id'] = unique_sellers\n",
    "scores['revenues'] = scores.seller_id.map(seller_revenues)\n",
    "scores['count_orders'] = scores.seller_id.map(seller_orders)\n",
    "scores['days_last_activity'] = scores.seller_id.map(timestamps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = range(1,6)\n",
    "scores['recency'] = pd.qcut(scores.days_last_activity,q=5, labels=labels)\n",
    "scores['frequency'] = pd.qcut(scores.count_orders,q=5, labels=labels)\n",
    "scores['monetary_ratio'] = pd.qcut(scores.revenues,q=5, labels=labels)\n",
    "scores['rfm_score'] = scores[['recency','frequency', 'monetary_ratio']].mean(axis=1).round(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "final = marketing.merge(scores[['seller_id','rfm_score']], on='seller_id', how='left')\n",
    "final = final.dropna(subset=['rfm_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}